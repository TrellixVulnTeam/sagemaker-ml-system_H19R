{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0c9f6b6",
   "metadata": {},
   "source": [
    "# Prepare session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.local import LocalSession\n",
    "import s3fs\n",
    "import subprocess\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "image_name = \"sagemaker-test\"\n",
    "ecr_namespace = image_name + \"/\"\n",
    "default_bucket = \"prod-test\"\n",
    "default_uri = \"s3://\" + default_bucket\n",
    "atf_s3_uri = default_uri + \"/sagemaker\"\n",
    "\n",
    "role = get_execution_role()\n",
    "account_id = role.split(\":\")[4]\n",
    "boto_session = boto3.Session()\n",
    "region = boto_session.region_name\n",
    "bucket = default_bucket\n",
    "\n",
    "sagemaker_session = sagemaker.Session(\n",
    "    boto_session=boto_session,\n",
    "    default_bucket=default_bucket\n",
    ")\n",
    "    \n",
    "s3_helper = s3fs.S3FileSystem()\n",
    "data_location_uri = default_uri + \"/training_data/full\"\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(sagemaker_session)\n",
    "print(default_uri)\n",
    "print(atf_s3_uri)\n",
    "print(data_location_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d14681",
   "metadata": {},
   "source": [
    "# Dev in real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41181ba3",
   "metadata": {},
   "source": [
    "## Build and push image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4a8e7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cd container && bash build_image.sh $image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c10aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! cd container && bash push_image.sh $image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d930d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_client = boto3.client('ecr')\n",
    "response = ecr_client.describe_images(\n",
    "    repositoryName=image_name,\n",
    "    imageIds=[{'imageTag': 'latest'}],\n",
    ")\n",
    "str(response[\"imageDetails\"][0][\"imagePushedAt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603efe0",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b05a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ml_dir = \"/opt/ml/processing\"\n",
    "execution_id = \"exp-real-sm\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest\"\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ba022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_instance_count = 1\n",
    "processing_instance_type = \"ml.m5.2xlarge\"\n",
    "training_instance_type = \"ml.m5.2xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5340c40",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102031d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "processor = ScriptProcessor(\n",
    "    base_job_name=\"prepare-data-processor\",\n",
    "    image_uri=image_uri,\n",
    "    command=['python'], # IMPORTANT, DEPENDS ON DOCKERFILE, DON'T USE python3\n",
    "    role=role,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    max_runtime_in_seconds=1200,\n",
    ")\n",
    "\n",
    "# IMPORTANT: ProcessingOutput MUST BE A FOLDER WITHOUT ANY NESTED FOLDER INSIDE\n",
    "# Otherwise it will raise Permission Denied when it performs post processes\n",
    "# Example: source CANNOT BE \"/opt/ml/processing/output/prepared_data\" because there're 2 nested folders inside\n",
    "\n",
    "processor.run(\n",
    "    code=\"container/code/prepare_data.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=data_location_uri,\n",
    "            destination=opt_ml_dir + \"/input\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=opt_ml_dir + \"/train\",\n",
    "            destination=atf_s3_uri + f\"/prepared_data/{execution_id}/train\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=opt_ml_dir + \"/test\",\n",
    "            destination=atf_s3_uri + f\"/prepared_data/{execution_id}/test\"\n",
    "        ),\n",
    "    ],\n",
    "    wait=True,\n",
    "    logs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c3f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect uploaded data\n",
    "preprocessing_job_description = processor.jobs[-1].describe()\n",
    "output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"train\":\n",
    "        train_data_uri = output[\"S3Output\"][\"S3Uri\"]\n",
    "    if output[\"OutputName\"] == \"test\":\n",
    "        test_data_uri = output[\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "! aws s3 ls $train_data_uri/\n",
    "! aws s3 ls $test_data_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9af0b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7b707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# JSON encode hyperparameters\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters({\n",
    "    \"learning_rate\": 0.05,\n",
    "})\n",
    "\n",
    "est = sagemaker.estimator.Estimator(\n",
    "    image_uri,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=atf_s3_uri + f\"/model\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_run=600, # timeout in seconds\n",
    "    disable_profiler=True,\n",
    "    use_spot_instances=True,\n",
    "    max_wait=600, # <= max_run\n",
    ")\n",
    "\n",
    "est.fit({\"train\": train_data_uri})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7a1800",
   "metadata": {},
   "source": [
    "### Inspect trained model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7248a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = est.latest_training_job.name\n",
    "print(job_name)\n",
    "\n",
    "training_job_description = est.jobs[-1].describe()\n",
    "print(training_job_description['TrainingJobStatus'])\n",
    "print(training_job_description['SecondaryStatus'])\n",
    "\n",
    "model_data_s3_uri = f\"{training_job_description['ModelArtifacts']['S3ModelArtifacts']}\"\n",
    "print(model_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77755444",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_helper.listdir(atf_s3_uri + f\"/model/{job_name}/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82fc942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print out logs from Cloud Watch\n",
    "logs = boto3.client(\"logs\")\n",
    "\n",
    "log_res = logs.describe_log_streams(\n",
    "    logGroupName=\"/aws/sagemaker/TrainingJobs\", logStreamNamePrefix=job_name\n",
    ")\n",
    "\n",
    "for log_stream in log_res[\"logStreams\"]:\n",
    "    # get one log event\n",
    "    log_event = logs.get_log_events(\n",
    "        logGroupName=\"/aws/sagemaker/TrainingJobs\", logStreamName=log_stream[\"logStreamName\"]\n",
    "    )\n",
    "\n",
    "    # print out messages from the log event\n",
    "    for ev in log_event[\"events\"]:\n",
    "        for k, v in ev.items():\n",
    "            if k == \"message\":\n",
    "                print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1c7f0",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698df836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt_ml_dir)\n",
    "evaluation_filename = \"eval.json\"\n",
    "print(evaluation_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7bc825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "eval_processor = ScriptProcessor(\n",
    "    base_job_name=\"evaluate-processor\",\n",
    "    image_uri=image_uri,\n",
    "    command=['python'],\n",
    "    role=role,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    max_runtime_in_seconds=1200,\n",
    ")\n",
    "\n",
    "eval_processor.run(\n",
    "    code=\"container/code/evaluate.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=model_data_s3_uri,\n",
    "            destination=opt_ml_dir + \"/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=test_data_uri,\n",
    "            destination=opt_ml_dir + \"/test\"\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=opt_ml_dir + \"/evaluation\",\n",
    "            destination=atf_s3_uri + f\"/evaluation/{execution_id}\"\n",
    "        ),\n",
    "    ],\n",
    "    wait=True,\n",
    "    logs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_job_description = eval_processor.jobs[-1].describe()\n",
    "eval_output_config = eval_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in eval_output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"evaluation\":\n",
    "        eval_uri = output[\"S3Output\"][\"S3Uri\"]\n",
    "        \n",
    "! aws s3 ls $eval_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a07c5",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2273303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import CSVSerializer\n",
    "predictor = est.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    serializer=CSVSerializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf27040",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "runtime = boto3.Session().client(\"runtime.sagemaker\")\n",
    "print(endpoint_name)\n",
    "print(runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc9191",
   "metadata": {},
   "source": [
    "## Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06535ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=default_bucket, Key=f'sagemaker/prepared_data/{execution_id}/train/train.csv')\n",
    "train_df = pd.read_csv(obj['Body']) # 'Body' is a key word\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a14fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = train_df.drop(train_df.columns[[0]], axis=1)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae062d3",
   "metadata": {},
   "source": [
    "### Test endpoint using predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23900fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_results(results):\n",
    "    return list(map(float, results.split('\\n')[:-1]))\n",
    "results = predictor.predict(test_data.values).decode('utf-8')\n",
    "format_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e9265",
   "metadata": {},
   "source": [
    "### Test endpoint using invoke_endpoint function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948dbb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=CSVSerializer().serialize(test_data.values),\n",
    "    ContentType='text/csv',\n",
    ")\n",
    "format_results(response['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef14c78",
   "metadata": {},
   "source": [
    "### Test endpoint using invoke_endpoint command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f1117",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_str = CSVSerializer().serialize(test_data.values)\n",
    "payload_file = \"./payload\"\n",
    "with open(payload_file, \"w\") as f:\n",
    "    f.write(test_data_str)\n",
    "! aws sagemaker-runtime invoke-endpoint --endpoint-name $endpoint_name --body fileb://./payload --content-type text/csv outfile.txt && cat outfile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d56b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print out logs from Cloud Watch\n",
    "logs = boto3.client(\"logs\")\n",
    "\n",
    "log_res = logs.describe_log_streams(\n",
    "    logGroupName=f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    ")\n",
    "\n",
    "for log_stream in log_res[\"logStreams\"]:\n",
    "    # get one log event\n",
    "    log_event = logs.get_log_events(\n",
    "        logGroupName=f\"/aws/sagemaker/Endpoints/{endpoint_name}\", logStreamName=log_stream[\"logStreamName\"]\n",
    "    )\n",
    "\n",
    "    # print out messages from the log event\n",
    "    for ev in log_event[\"events\"]:\n",
    "        for k, v in ev.items():\n",
    "            if k == \"message\":\n",
    "                print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09ae3993",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4d164d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm payload && rm outfile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a86bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
